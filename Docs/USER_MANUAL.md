# MFSU Comet Analysis - User Manual

**Version:** 1.0.0  
**Author:** Miguel √Ångel Franco Le√≥n & Claude  
**Date:** September 2025

A comprehensive guide for using the MFSU (Unified Fractal-Stochastic Model) framework for astronomical object analysis, with focus on comets and other celestial bodies.

## Table of Contents

1. [Introduction](#introduction)
2. [Quick Start Guide](#quick-start-guide)
3. [Basic Usage](#basic-usage)
4. [Advanced Features](#advanced-features)
5. [Case Studies](#case-studies)
6. [Data Requirements](#data-requirements)
7. [Scientific Interpretation](#scientific-interpretation)
8. [Troubleshooting](#troubleshooting)
9. [Best Practices](#best-practices)
10. [FAQ](#frequently-asked-questions)

---

## Introduction

### What is MFSU?

The Unified Fractal-Stochastic Model (MFSU) is a theoretical framework for analyzing fractal structures in astronomical observations. This package provides tools to:

- **Measure fractal dimensions** of celestial objects
- **Analyze radial intensity profiles** with power-law fitting
- **Compare results** with MFSU theoretical predictions
- **Generate publication-quality visualizations**
- **Validate scientific results** with robust statistics

### Key Features

‚úÖ **Scientific Rigor**: Based on peer-reviewed MFSU theoretical framework  
‚úÖ **JWST Ready**: Optimized for James Webb Space Telescope data  
‚úÖ **Publication Quality**: Professional plots and comprehensive analysis  
‚úÖ **Robust Validation**: Extensive error checking and quality assessment  
‚úÖ **Easy to Use**: Simple API with sensible defaults  

### Target Applications

- **Comet structure analysis** (primary use case)
- **Asteroid morphology characterization**
- **Galaxy structure studies**
- **Nebula and star formation region analysis**
- **Any extended astronomical object with fractal properties**

---

## Quick Start Guide

### 30-Second Analysis

The fastest way to analyze your data:

```python
from mfsu_comet_analysis import run_complete_analysis

# Run complete analysis with one function call
analyzer, image, results = run_complete_analysis()

# View results
print(f"Fractal dimension: {results['df_measured']:.3f} ¬± {results['df_error']:.3f}")
print(f"MFSU agreement: {results['mfsu_agreement']}")
```

### 5-Minute Analysis with Your Data

```python
from mfsu_comet_analysis.core import MFSUCometReal
from mfsu_comet_analysis.preprocessing import AstronomicalPreprocessor

# Initialize
analyzer = MFSUCometReal()
preprocessor = AstronomicalPreprocessor()

# Load your FITS file
image, metadata = preprocessor.load_image("your_comet_data.fits")

# Preprocess
processed_image, prep_data = preprocessor.preprocess_image(image)

# Analyze
box_data = analyzer.advanced_box_counting(processed_image, prep_data['detection_threshold'])
radial_data = analyzer.advanced_radial_analysis(processed_image, prep_data['detection_threshold'])

# Interpret
df, df_err = box_data[0], box_data[1]
alpha, alpha_err = radial_data[0], radial_data[1]
results = analyzer.scientific_interpretation(df, df_err, alpha, alpha_err)

# Visualize
analyzer.create_publication_plots(image, processed_image, prep_data, 
                                box_data, radial_data, results)
```

---

## Basic Usage

### Step 1: Import the Package

```python
# Core functionality
from mfsu_comet_analysis.core import MFSUCometReal

# Individual modules for advanced use
from mfsu_comet_analysis.fractal_analysis import FractalAnalyzer
from mfsu_comet_analysis.preprocessing import AstronomicalPreprocessor
from mfsu_comet_analysis.visualization import MFSUVisualizer
from mfsu_comet_analysis.utils import validate_image_data, AnalysisLogger
```

### Step 2: Load and Validate Your Data

#### Loading Different File Formats

```python
from mfsu_comet_analysis.preprocessing import DataLoader, AstronomicalPreprocessor

preprocessor = AstronomicalPreprocessor()

# FITS files (recommended for astronomical data)
image, metadata = DataLoader.load_fits("observation.fits")

# JWST pipeline products (automatic metadata extraction)
image, metadata = DataLoader.load_jwst_pipeline("jwst_stage2.fits")

# Standard image formats (PNG, JPEG, TIFF)
image, metadata = preprocessor.load_image("comet_image.png")

# NumPy arrays directly
import numpy as np
your_array = np.load("data_array.npy")
image, metadata = preprocessor.load_image(image_data=your_array)
```

#### Data Validation

```python
from mfsu_comet_analysis.utils import validate_image_data, ValidationError

try:
    validate_image_data(image, min_size=64, max_size=4096)
    print("‚úÖ Image validation passed")
except ValidationError as e:
    print(f"‚ùå Validation failed: {e}")
```

### Step 3: Preprocess Your Image

```python
# Initialize preprocessor
preprocessor = AstronomicalPreprocessor(
    default_pixel_scale=0.12,  # JWST IFU typical scale
    detection_sigma=3.0        # 3-sigma detection threshold
)

# Preprocess with different methods
processed_image, prep_data = preprocessor.preprocess_image(
    image,
    background_method='corners',  # 'corners', 'sigma_clip', 'percentile'
    noise_method='mad',          # 'mad', 'std', 'robust'
    verbose=True
)

# Check preprocessing quality
quality_report = preprocessor.create_quality_report(
    image, processed_image, prep_data, verbose=True
)

if quality_report['preprocessing_quality']['suitable_for_fractal_analysis']:
    print("‚úÖ Data quality suitable for analysis")
else:
    print("‚ö†Ô∏è Data quality issues detected:")
    for flag in quality_report['preprocessing_quality']['quality_flags']:
        print(f"  - {flag}")
```

### Step 4: Perform Fractal Analysis

#### Box-Counting Analysis

```python
from mfsu_comet_analysis.fractal_analysis import FractalAnalyzer

# Initialize analyzer with your pixel scale
analyzer = FractalAnalyzer(pixel_scale=metadata.get('pixel_scale_linear', 0.12))

# Perform box-counting analysis
df, df_error, scales, counts, r_squared, box_sizes = analyzer.advanced_box_counting(
    processed_image,
    prep_data['detection_threshold'],
    n_scales=8,           # Number of different box sizes to try
    verbose=True
)

print(f"Fractal dimension: {df:.3f} ¬± {df_error:.3f} (R¬≤ = {r_squared:.4f})")
```

#### Radial Profile Analysis

```python
# Perform radial profile analysis
alpha, alpha_error, radii, intensities, r_squared_radial, errors = analyzer.advanced_radial_analysis(
    processed_image,
    prep_data['detection_threshold'],
    center=None,          # Automatic photometric center
    n_bins=20,           # Number of radial bins
    verbose=True
)

print(f"Radial slope: Œ± = {alpha:.3f} ¬± {alpha_error:.3f} (R¬≤ = {r_squared_radial:.4f})")
```

### Step 5: Scientific Interpretation

```python
# Comprehensive scientific interpretation
results = analyzer.scientific_interpretation(
    df, df_error, alpha, alpha_error, verbose=True
)

# Key results
print(f"Measured df: {results['df_measured']:.3f}")
print(f"Derived Œ¥p: {results['delta_derived']:.3f}")
print(f"MFSU agreement: {results['mfsu_agreement']}")
print(f"Statistical significance: {results['df_sigma']:.1f}œÉ")
print(f"Structure classification: {results['df_class']}")
print(f"Profile classification: {results['alpha_class']}")
```

### Step 6: Create Visualizations

```python
from mfsu_comet_analysis.visualization import MFSUVisualizer

# Initialize visualizer
visualizer = MFSUVisualizer(style='publication', dpi=300)

# Prepare data tuples for plotting
box_data = (df, df_error, scales, counts, r_squared, box_sizes)
radial_data = (alpha, alpha_error, radii, intensities, r_squared_radial, errors)

# Create comprehensive analysis plot
fig = visualizer.create_comprehensive_analysis_plot(
    original_image=image,
    processed_image=processed_image,
    preprocessing_data=prep_data,
    box_data=box_data,
    radial_data=radial_data,
    interpretation_results=results,
    pixel_scale=analyzer.pixel_scale,
    save_path="comet_analysis_complete.png",
    show=True
)
```

---

## Advanced Features

### Custom Analysis Configuration

```python
from mfsu_comet_analysis.utils import AnalysisConfig

# Create custom configuration
config = AnalysisConfig(
    min_box_size=8,              # Larger minimum box size
    max_scales=12,               # More scales for better statistics
    min_pixels_per_box=0.1,      # More sensitive detection
    detection_sigma=2.5,         # Lower detection threshold
    min_r_squared=0.85          # Higher quality requirement
)

# Use custom configuration
analyzer = FractalAnalyzer(pixel_scale=0.08)
```

### Advanced Preprocessing Options

#### Background Subtraction Methods

```python
# Method 1: Corner-based (default, good for point sources)
processed1, prep1 = preprocessor.preprocess_image(image, background_method='corners')

# Method 2: Sigma-clipping (good for extended sources)
processed2, prep2 = preprocessor.preprocess_image(image, background_method='sigma_clip')

# Method 3: Percentile-based (robust for contaminated images)
processed3, prep3 = preprocessor.preprocess_image(image, background_method='percentile')
```

#### Noise Estimation Methods

```python
# Method 1: Median Absolute Deviation (default, most robust)
processed, prep = preprocessor.preprocess_image(image, noise_method='mad')

# Method 2: Standard deviation (fastest)
processed, prep = preprocessor.preprocess_image(image, noise_method='std')

# Method 3: Robust percentile-based (good for outliers)
processed, prep = preprocessor.preprocess_image(image, noise_method='robust')
```

### Multi-Object Analysis

```python
def analyze_multiple_objects(file_list):
    """Analyze multiple objects and compare results."""
    results_list = []
    
    for filename in file_list:
        print(f"\nüìä Analyzing {filename}...")
        
        # Load and analyze
        image, metadata = preprocessor.load_image(filename)
        processed, prep_data = preprocessor.preprocess_image(image)
        
        # Analysis
        box_data = analyzer.advanced_box_counting(processed, prep_data['detection_threshold'])
        radial_data = analyzer.advanced_radial_analysis(processed, prep_data['detection_threshold'])
        
        # Store results
        results = {
            'filename': filename,
            'df': box_data[0],
            'df_error': box_data[1],
            'alpha': radial_data[0],
            'alpha_error': radial_data[1],
            'r2_box': box_data[4],
            'r2_radial': radial_data[4]
        }
        results_list.append(results)
    
    return results_list

# Example usage
comet_files = ['comet1.fits', 'comet2.fits', 'comet3.fits']
comparison_results = analyze_multiple_objects(comet_files)

# Statistical comparison
dfs = [r['df'] for r in comparison_results]
print(f"Mean df: {np.mean(dfs):.3f} ¬± {np.std(dfs):.3f}")
```

### Custom Visualization Styles

```python
# Publication style (default)
viz_pub = MFSUVisualizer(style='publication', dpi=300)

# Presentation style (larger fonts, thicker lines)
viz_pres = MFSUVisualizer(style='presentation', dpi=150)

# Custom figure sizes
viz_custom = MFSUVisualizer(
    style='publication', 
    figsize_large=(24, 16),
    figsize_medium=(20, 12)
)

# Create focused plots
box_fig = viz_pub.create_focused_box_counting_plot(
    scales, counts, df, df_error, r_squared,
    save_path="box_counting_analysis.pdf"
)

radial_fig = viz_pub.create_focused_radial_plot(
    radii, intensities, errors, alpha, alpha_error, r_squared_radial,
    save_path="radial_profile_analysis.pdf"
)
```

---

## Case Studies

### Case Study 1: Comet 31/ATLAS Analysis

This is the primary validation case for the MFSU framework.

```python
# Comet 31/ATLAS specific analysis
def analyze_comet_31_atlas():
    """Complete analysis of Comet 31/ATLAS as validation case."""
    
    # Initialize with JWST IFU parameters
    analyzer = MFSUCometReal()
    
    # Load JWST data (if available) or use high-fidelity simulation
    comet_image = analyzer.load_jwst_image()
    
    # Full analysis pipeline
    processed_image, prep_data = analyzer.preprocess_image(comet_image)
    box_data = analyzer.advanced_box_counting(processed_image, prep_data)
    radial_data = analyzer.advanced_radial_analysis(processed_image, prep_data)
    
    # Scientific interpretation
    df, df_err = box_data[0], box_data[1]
    alpha, alpha_err = radial_data[0], radial_data[1]
    results = analyzer.scientific_interpretation(df, df_err, alpha, alpha_err)
    
    # Expected results for validation:
    # df ‚âà 1.906 ¬± 0.033 (complex multi-component structure)
    # Œ± ‚âà 0.720 ¬± 0.083 (extended gas-dominated coma)
    
    print("üéØ COMET 31/ATLAS VALIDATION RESULTS:")
    print(f"   Fractal dimension: df = {df:.3f} ¬± {df_err:.3f}")
    print(f"   Expected range: 1.87 - 1.94")
    print(f"   Radial slope: Œ± = {alpha:.3f} ¬± {alpha_err:.3f}")
    print(f"   Expected range: 0.64 - 0.80")
    
    # MFSU comparison
    print(f"\nüî¨ MFSU FRAMEWORK VALIDATION:")
    print(f"   MFSU theoretical df: 2.079")
    print(f"   Deviation: {results['df_sigma']:.1f}œÉ")
    print(f"   Agreement: {results['mfsu_agreement']}")
    
    return results

# Run validation
validation_results = analyze_comet_31_atlas()
```

### Case Study 2: Asteroid Belt Object

```python
def analyze_asteroid(image_path):
    """Analyze asteroid morphology with MFSU framework."""
    
    # Asteroids typically have different characteristics than comets
    # Expected df range: 1.2 - 1.6 (more compact structures)
    # Expected Œ± range: 1.5 - 3.0 (steeper profiles)
    
    preprocessor = AstronomicalPreprocessor(detection_sigma=2.5)  # More sensitive
    analyzer = FractalAnalyzer(pixel_scale=0.05)  # Higher resolution typical
    
    # Load and analyze
    image, metadata = preprocessor.load_image(image_path)
    processed, prep_data = preprocessor.preprocess_image(image)
    
    # Analysis with asteroid-specific parameters
    box_data = analyzer.advanced_box_counting(
        processed, prep_data['detection_threshold'],
        n_scales=6  # Fewer scales for smaller objects
    )
    
    radial_data = analyzer.advanced_radial_analysis(
        processed, prep_data['detection_threshold'],
        n_bins=15  # Fewer bins for smaller objects
    )
    
    # Interpretation
    df, df_err = box_data[0], box_data[1]
    alpha, alpha_err = radial_data[0], radial_data[1]
    
    # Asteroid-specific interpretation
    if df < 1.4:
        structure_type = "Regular/spheroidal asteroid"
    elif df < 1.7:
        structure_type = "Moderately irregular asteroid"
    else:
        structure_type = "Highly irregular/contact binary asteroid"
    
    print(f"Asteroid classification: {structure_type}")
    print(f"Fractal dimension: {df:.3f} ¬± {df_err:.3f}")
    
    return {
        'df': df, 'df_error': df_err, 'alpha': alpha, 'alpha_error': alpha_err,
        'classification': structure_type
    }
```

### Case Study 3: Galaxy Structure Analysis

```python
def analyze_galaxy_structure(galaxy_image_path):
    """Analyze galaxy spiral structure using MFSU framework."""
    
    # Galaxies have different scale considerations
    analyzer = FractalAnalyzer(pixel_scale=0.25)  # Typical galaxy survey scale
    preprocessor = AstronomicalPreprocessor(detection_sigma=2.0)
    
    # Load galaxy image
    image, metadata = preprocessor.load_image(galaxy_image_path)
    processed, prep_data = preprocessor.preprocess_image(
        image, background_method='sigma_clip'  # Better for extended sources
    )
    
    # Galaxy-specific analysis
    box_data = analyzer.advanced_box_counting(
        processed, prep_data['detection_threshold'],
        n_scales=10  # More scales for extended structure
    )
    
    radial_data = analyzer.advanced_radial_analysis(
        processed, prep_data['detection_threshold'],
        n_bins=30  # More bins for extended profiles
    )
    
    # Interpretation for galaxies
    df, df_err = box_data[0], box_data[1]
    
    if df < 1.8:
        galaxy_type = "Smooth/elliptical-like structure"
    elif df < 2.2:
        galaxy_type = "Moderate spiral structure"
    else:
        galaxy_type = "Complex spiral/irregular structure"
    
    print(f"Galaxy structure: {galaxy_type}")
    print(f"Fractal dimension: {df:.3f} ¬± {df_err:.3f}")
    
    return {'df': df, 'df_error': df_err, 'structure_type': galaxy_type}
```

---

## Data Requirements

### Image Quality Requirements

| **Parameter** | **Minimum** | **Recommended** | **Maximum** |
|---------------|-------------|-----------------|-------------|
| **Resolution** | 64√ó64 pixels | 256√ó256 pixels | 4096√ó4096 pixels |
| **Signal-to-Noise** | S/N > 5 | S/N > 20 | S/N > 1000 |
| **Detection Fraction** | >0.5% | 1-20% | <70% |
| **Dynamic Range** | >10:1 | >100:1 | >10000:1 |
| **Bit Depth** | 8-bit | 16-bit | 32-bit float |

### File Format Support

‚úÖ **FITS** (recommended for astronomy)
- Standard FITS files (.fits, .fit)
- JWST pipeline products (automatic metadata)
- Multi-extension FITS with HDU selection

‚úÖ **Standard Images**
- PNG (lossless, good for processed images)
- TIFF (uncompressed, good for scientific data)
- JPEG (acceptable for quick analysis, lossy compression)

‚úÖ **NumPy Arrays**
- Direct array input (.npy files)
- Programmatic data input
- Custom data formats

### Pixel Scale Requirements

| **Object Type** | **Typical Scale** | **Recommended Range** |
|-----------------|-------------------|-----------------------|
| **Comets (JWST)** | 0.12 arcsec/pixel | 0.08 - 0.20 arcsec/pixel |
| **Asteroids** | 0.05 arcsec/pixel | 0.03 - 0.10 arcsec/pixel |
| **Galaxies** | 0.25 arcsec/pixel | 0.15 - 0.50 arcsec/pixel |
| **Star Formation Regions** | 0.10 arcsec/pixel | 0.05 - 0.25 arcsec/pixel |

### Data Preprocessing Best Practices

1. **Background Subtraction**
   - Use 'corners' method for point sources
   - Use 'sigma_clip' for extended sources
   - Use 'percentile' for contaminated fields

2. **Noise Estimation**
   - Use 'mad' method for most robust results
   - Use 'std' for fastest processing
   - Use 'robust' for outlier-contaminated data

3. **Detection Threshold**
   - 3œÉ standard for most astronomical data
   - 2.5œÉ for faint source detection
   - 4œÉ for conservative analysis

---

## Scientific Interpretation

### Understanding Fractal Dimension (df)

The fractal dimension quantifies the complexity of the object's structure:

| **df Range** | **Interpretation** | **Typical Objects** |
|--------------|-------------------|-------------------|
| **1.0 - 1.4** | Simple, smooth structure | Inactive nuclei, regular asteroids |
| **1.4 - 1.7** | Moderate complexity | Active comets, moderate activity |
| **1.7 - 2.1** | Complex structure | Multi-jet comets, irregular asteroids |
| **2.1 - 2.5** | Highly complex | Outbursting comets, contact binaries |
| **>2.5** | Extremely complex | Fragmenting objects, unusual morphology |

### Understanding Radial Slope (Œ±)

The radial slope describes how intensity falls off with distance:

| **Œ± Range** | **Interpretation** | **Physical Meaning** |
|-------------|-------------------|---------------------|
| **0.5 - 1.0** | Very shallow profile | Extended gas coma, high gas/dust ratio |
| **1.0 - 1.5** | Moderate profile | Typical comet distribution |
| **1.5 - 2.5** | Steep profile | Dust-dominated, concentrated activity |
| **2.5 - 3.5** | Very steep | Point-source dominated, inactive |
| **>3.5** | Extremely steep | Stellar-like, minimal coma |

### MFSU Framework Interpretation

The MFSU theoretical predictions:
- **df = 2.079 ¬± 0.003** (cosmic microwave background derived)
- **Œ¥p = 0.921 ¬± 0.003** (where Œ¥p = 3 - df)

**Agreement Levels:**
- **<1œÉ deviation**: Excellent agreement - MFSU strongly supported
- **1-2œÉ deviation**: Good agreement - MFSU supported
- **2-3œÉ deviation**: Moderate agreement - MFSU partially supported
- **>3œÉ deviation**: Poor agreement - Object shows distinct characteristics

### Physical Interpretation Guidelines

1. **For Comets:**
   - df < 1.7: Simple nucleus with basic coma
   - df 1.7-2.1: Complex activity with jets/fans
   - df > 2.1: Fragmentation or outburst activity

2. **For Asteroids:**
   - df < 1.4: Regular, intact object
   - df 1.4-1.8: Moderately irregular shape
   - df > 1.8: Highly irregular or contact binary

3. **For Extended Objects:**
   - df < 1.8: Smooth, regular structure
   - df 1.8-2.2: Filamentary or spiral structure
   - df > 2.2: Highly complex, turbulent structure

---

## Troubleshooting

### Common Error Messages

#### `ValidationError: Image must be 2D`
**Cause:** Loaded a color image or 3D array  
**Solution:** Convert to grayscale or select single channel
```python
if image.ndim == 3:
    image = np.mean(image, axis=2)  # Convert RGB to grayscale
```

#### `ValidationError: Image too small`
**Cause:** Image resolution below minimum (32√ó32)  
**Solution:** Use higher resolution data or interpolate
```python
from scipy.ndimage import zoom
image_upsampled = zoom(image, 2.0)  # Double the resolution
```

#### `ValueError: Insufficient scales for analysis`
**Cause:** Not enough box sizes for fractal analysis  
**Solution:** Reduce min_box_size or use larger images
```python
config = AnalysisConfig(min_box_size=2)  # Smaller minimum box size
```

#### `RuntimeError: No significant signal detected`
**Cause:** Detection threshold too high or very faint object  
**Solution:** Lower detection threshold
```python
preprocessor = AstronomicalPreprocessor(detection_sigma=2.0)  # Lower threshold
```

### Performance Issues

#### Slow Analysis
**Causes:**
- Very large images (>2048√ó2048)
- Too many scales (>12)
- Too many radial bins (>30)

**Solutions:**
```python
# Reduce image size
from scipy.ndimage import zoom
image_small = zoom(image, 0.5)  # Half size

# Reduce analysis parameters
box_data = analyzer.advanced_box_counting(image, threshold, n_scales=6)
radial_data = analyzer.advanced_radial_analysis(image, threshold, n_bins=15)
```

#### Memory Issues
**Cause:** Large images or saving full analysis results  
**Solutions:**
```python
# Save without images
save_analysis_results(results, "results.json", include_images=False)

# Process in chunks for very large images
def process_large_image(large_image, chunk_size=1024):
    # Implementation for chunked processing
    pass
```

### Quality Issues

#### Low R¬≤ Values
**Causes:**
- Insufficient dynamic range
- Poor background subtraction
- Object too small for analysis

**Solutions:**
```python
# Check preprocessing quality
quality_report = preprocessor.create_quality_report(image, processed, prep_data)
if not quality_report['preprocessing_quality']['suitable_for_fractal_analysis']:
    # Try different preprocessing methods
    processed, prep_data = preprocessor.preprocess_image(
        image, background_method='sigma_clip'
    )
```

#### Unusual Parameter Values
**Cause:** Object outside typical range or analysis artifacts  
**Solution:** Validate with visual inspection
```python
# Create diagnostic plots
visualizer.create_image_comparison_plot(image, processed, prep_data, pixel_scale)
```

---

## Best Practices

### Data Preparation

1. **Always validate your data first**
   ```python
   validate_image_data(image)
   validate_pixel_scale(pixel_scale)
   ```

2. **Use appropriate pixel scales**
   - Match the scale to your object type
   - Verify scale with metadata when available

3. **Check preprocessing quality**
   ```python
   quality_report = preprocessor.create_quality_report(...)
   assert quality_report['preprocessing_quality']['suitable_for_fractal_analysis']
   ```

### Analysis Strategy

1. **Start with default parameters**
   - Use defaults for initial analysis
   - Customize only if needed

2. **Validate results**
   ```python
   validation = validate_analysis_results(box_data, radial_data)
   print(f"Quality score: {validation['quality_score']}/10")
   ```

3. **Compare multiple methods**
   ```python
   # Try different background methods
   for method in ['corners', 'sigma_clip', 'percentile']:
       processed, prep_data = preprocessor.preprocess_image(image, background_method=method)
       # Analyze and compare results
   ```

### Publication Guidelines

1. **Always report uncertainties**
   ```python
   print(f"df = {df:.3f} ¬± {df_error:.3f}")
   ```

2. **Include quality metrics**
   ```python
   print(f"Box-counting R¬≤ = {r_squared:.4f}")
   print(f"Number of scales = {len(scales)}")
   ```

3. **Provide full methodology**
   - Report all parameters used
   - Include preprocessing details
   - Mention software version

4. **Save publication plots**
   ```python
   visualizer.create_comprehensive_analysis_plot(
       ..., save_path="publication_figure.pdf", dpi=300
   )
   ```

### Batch Processing

```python
def batch_analyze_directory(data_directory):
    """Analyze all FITS files in a directory."""
    
    from pathlib import Path
    import json
    
    data_dir = Path(data_directory)
    results_all = {}
    
    for fits_file in data_dir.glob("*.fits"):
        try:
            print(f"\nüìä Processing {fits_file.name}...")
            
            # Analysis pipeline
            image, metadata = preprocessor.load_image(str(fits_file))
            processed, prep_data = preprocessor.preprocess_image(image)
            
            # Quality check
            quality = preprocessor.create_quality_report(image, processed, prep_data, verbose=False)
            if not quality['preprocessing_quality']['suitable_for_fractal_analysis']:
                print(f"‚ö†Ô∏è Skipping {fits_file.name} - poor quality")
                continue
            
            # Fractal analysis
            box_data = analyzer.advanced_box_counting(processed, prep_data['detection_threshold'], verbose=False)
            radial_data = analyzer.advanced_radial_analysis(processed, prep_data['detection_threshold'], verbose=False)
            
            # Store results
            results_all[fits_file.name] = {
                'df': box_data[0],
                'df_error': box_data[1],
                'alpha': radial_data[0],
                'alpha_error': radial_data[1],
                'r2_box': box_data[4],
                'r2_radial': radial_data[4],
                'quality_score': quality['preprocessing_quality']['quality_score']
            }
            
            print(f"‚úÖ Success: df = {box_data[0]:.3f} ¬± {box_data[1]:.3f}")
            
        except Exception as e:
            print(f"‚ùå Error processing {fits_file.name}: {e}")
    
    # Save batch results
    with open(data_dir / "batch_results.json", 'w') as f:
        json.dump(results_all, f, indent=2)
    
    print(f"\nüìã Batch analysis complete: {len(results_all)} objects analyzed")
    return results_all
```

---

## Frequently Asked Questions

### General Questions

**Q: What types of astronomical objects can I analyze?**  
A: The MFSU framework works best with extended objects that have fractal-like structure: comets, asteroids, galaxy spiral arms, star-forming regions, and nebulae. It's less suitable for point sources or perfectly smooth objects.

**Q: Do I need special astronomical software?**  
A: No, the package is self-contained. However, for FITS file support, installing `astropy` is recommended but not required.

**Q: How accurate are the fractal dimension measurements?**  
A: Typical uncertainties are 0.01-0.05 for good quality data. The accuracy depends on image quality, object size, and signal-to-noise ratio.

### Technical Questions

**Q: What's the minimum image size for analysis?**  
A: 64√ó64 pixels minimum, but 256√ó256 or larger is recommended for reliable results.

**Q: How do I choose the right pixel scale?**  
A: Use the metadata from your telescope/instrument. If unknown, typical values are: JWST IFU (0.12"), HST (0.05"), ground-based (0.2-1.0").

**Q: Why do I get different results with different preprocessing methods?**  
A: Different background subtraction and noise estimation methods can affect the detected structure. Try multiple methods and use the one that gives the most stable results.

**Q: Can I analyze time-series data?**  
A: Yes, but you'll need to analyze each frame separately. The package doesn't currently support automatic time-series analysis.

### Scientific Questions

**Q: What does it mean if my object doesn't match MFSU predictions?**  
A: This is scientifically interesting! Objects with df significantly different from 2.079 may have different formation mechanisms or physical processes than those predicted by MFSU.

**Q: How do I compare results between different objects?**  
A: Use the same preprocessing parameters and analysis settings. Statistical comparison tools are provided in the utils module.

**Q: Can I use this for non-astronomical images?**  
A: The algorithms work on any 2D grayscale image, but the scientific interpretation is specific to astronomical objects.

### Citation and Publication

**Q: How do I cite this software?**  
A: ```
Franco Le√≥n, M. A. & Claude (2025). MFSU Comet Analysis: A Python package for fractal analysis of astronomical objects using the Unified Fractal-Stochastic Model. Version 1.0.0.
```

**Q: What should I include in publications?**  
A: Report all parameters used, preprocessing methods, quality metrics (R¬≤ values), number of data points, and software version. Include uncertainty estimates for all measured parameters.

---

## Getting Help

### Documentation
- **API Reference**: Complete function documentation
- **Installation Guide**: Setup and dependencies
- **Examples**: Working code examples in `/examples/`

### Troubleshooting
1. Check this manual's troubleshooting section
2. Validate your input data
3. Try with default parameters first
4. Check data quality metrics

### Contact
For questions, bug reports, or feature requests:
- Check existing documentation
- Review the troubleshooting section
- Contact the development team

---

*Happy analyzing! üåå*
